{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Input, Sequential, Model\n",
    "from keras.layers import Dense, LSTM, TimeDistributed, Masking, Bidirectional, concatenate, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = '../data/test/mexico_k_2_standard.csv'\n",
    "profile_file = '../data/profiles.csv'\n",
    "\n",
    "def get_data():\n",
    "    profiles_file = pd.read_csv(profile_file)\n",
    "    profiles_file = profiles_file[['profile_id', 'cwrb_reference_soil_group']]\n",
    "    data = pd.read_csv(inputfile)\n",
    "    data = profiles_file.merge(data, how=\"inner\", left_on=[\n",
    "        'profile_id'], right_on=['profile_id'])\n",
    "\n",
    "    data = remove_small_classes(data, 15)\n",
    "\n",
    "    y = data.cwrb_reference_soil_group.astype(str)\n",
    "    X = data.drop(['cwrb_reference_soil_group'], axis=1)\n",
    "\n",
    "    return X, y, data\n",
    "\n",
    "def remove_small_classes(df, min):\n",
    "    uniques = df.cwrb_reference_soil_group.unique()\n",
    "    for u in uniques:\n",
    "        cnt = df[df.cwrb_reference_soil_group == u].shape[0]\n",
    "        if cnt < min:\n",
    "            df = df[df.cwrb_reference_soil_group != u]\n",
    "            print('Deleting {} with {} occurrences'.format(u, cnt))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_data_structured():\n",
    "    profiles_file = pd.read_csv(profile_file)\n",
    "    profiles_file = profiles_file[['profile_id', 'cwrb_reference_soil_group']]\n",
    "    data = pd.read_csv(inputfile)\n",
    "    data = profiles_file.merge(data, how=\"inner\", left_on=[\n",
    "        'profile_id'], right_on=['profile_id'])\n",
    "\n",
    "    X, y, data = get_data()\n",
    "\n",
    "    # Treat Labels\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_Y = encoder.transform(y)\n",
    "    dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "    return X, dummy_y, encoder\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy(history):\n",
    "    plt.clf()\n",
    "    acc = history.history['acc']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    val_acc = history.history['val_acc']\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "def get_data_recurrent():\n",
    "    inputfile = '../data/mexico_k_1.csv'\n",
    "    profile_file = '../data/profiles.csv'\n",
    "    profiles_file = pd.read_csv(profile_file)\n",
    "    profiles_file = profiles_file[['profile_id', 'cwrb_reference_soil_group']]\n",
    "    data = pd.read_csv(inputfile)\n",
    "    data = profiles_file.merge(data, how=\"inner\", left_on=[\n",
    "        'profile_id'], right_on=['profile_id'])\n",
    "    \n",
    "    # Remove minority classes\n",
    "    data = data[data['cwrb_reference_soil_group'] !='Plinthosols']\n",
    "    data = data[data['cwrb_reference_soil_group'] !='Histosols']\n",
    "\n",
    "    data.fillna(-1., inplace=True)\n",
    "    profile_data, layer_data, y = treat_data(data)\n",
    "\n",
    "    # Treat Labels\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_Y = encoder.transform(y)\n",
    "    dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "    return profile_data, layer_data, dummy_y, encoder\n",
    "\n",
    "\n",
    "\n",
    "def treat_data(data):\n",
    "    profile_data = []\n",
    "    layer_data = []\n",
    "    profile_ids = data.profile_id.unique()\n",
    "    max_n_layers = data.profile_id.value_counts().head(1).values[0]\n",
    "    # All except latitude longitude profile id and class\n",
    "    features_per_layer = len(data.columns) - 4\n",
    "    y = []\n",
    "\n",
    "    for i, id in enumerate(profile_ids):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        # Find the layers for this profile and sort them\n",
    "        layers = data[data['profile_id'] == id]\n",
    "        layers = layers.sort_values(by=['lower_depth'])\n",
    "\n",
    "        # Add the layer, filling the missing layers with 0\n",
    "        layer = np.zeros([max_n_layers, features_per_layer])\n",
    "        for j, l in enumerate(layers.drop(['profile_id', 'cwrb_reference_soil_group', 'latitude', 'longitude'], axis=1).values):\n",
    "            layer[j] = l\n",
    "        layer_data.append(layer)\n",
    "\n",
    "        # Fill the profile data\n",
    "        profile = layers.iloc[0][['latitude', 'longitude', 'profile_id']]\n",
    "        profile_data.append(profile.values)\n",
    "\n",
    "        y.append(layers.iloc[0].cwrb_reference_soil_group)\n",
    "\n",
    "    return np.array(profile_data).reshape(len(profile_data), 3), np.array(layer_data), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Results from Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Plinthosols with 6 occurrences\n",
      "Deleting Histosols with 10 occurrences\n",
      "Deleting Plinthosols with 6 occurrences\n",
      "Deleting Histosols with 10 occurrences\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "# Create DataSets\n",
    "\n",
    "random = np.random.randint(100)\n",
    "X, y, final_data = get_data()\n",
    "\n",
    "# Tree Based\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=random)\n",
    "\n",
    "# Neural Network\n",
    "X_seq, y_seq, encoder_seq = get_data_structured()\n",
    "\n",
    "bools_seq = []\n",
    "for p in X_seq['profile_id']: \n",
    "    bools_seq.append(p in list(X_train['profile_id']))\n",
    "\n",
    "X_train_seq = X_seq[bools_seq]\n",
    "X_test_seq = X_seq[np.logical_not(bools_seq)]\n",
    "y_train_seq = y_seq[bools_seq]\n",
    "y_test_seq = y_seq[np.logical_not(bools_seq)]\n",
    "#X_seq, y_seq, encoder_seq = get_data_structured()\n",
    "#X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(\n",
    "#    X_seq, y_seq, test_size=0.2, stratify=y_seq, random_state=random)\n",
    "\n",
    "# Recurrent Neural Network\n",
    "X_rec_profile, X_rec_layer, y_rec, encoder_rec = get_data_recurrent()\n",
    "\n",
    "bools_rec = []\n",
    "for p in X_rec_profile[:,2]: \n",
    "    bools_rec.append(p in list(X_train['profile_id']))\n",
    "\n",
    "X_train_profile = X_rec_profile[bools_rec]\n",
    "X_test_profile = X_rec_profile[np.logical_not(bools_rec)]\n",
    "X_train_layer = X_rec_layer[bools_rec]\n",
    "X_test_layer = X_rec_layer[np.logical_not(bools_rec)]\n",
    "y_train_rec = y_rec[bools_rec]\n",
    "y_test_rec = y_rec[np.logical_not(bools_rec)]\n",
    "\n",
    "#X_rec_profile, X_rec_layer, y_rec, encoder_rec = get_data_recurrent()\n",
    "#X_train_profile, X_test_profile, X_train_layer, X_test_layer, y_train_rec, y_test_rec = train_test_split(\n",
    "#    X_rec_profile, X_rec_layer, y_rec, test_size=0.2, stratify=y_rec, random_state=random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.4861903014607548, Accuracy: 0.5344699777613047, Time: 15.246674299240112\n"
     ]
    }
   ],
   "source": [
    "clf_RF = RandomForestClassifier(min_samples_split=6,\n",
    "                                n_estimators=1300, min_samples_leaf=2,\n",
    "                                oob_score=True, class_weight=\"balanced\", n_jobs=2)\n",
    "\n",
    "start = time.time()\n",
    "clf_RF.fit(X_train.drop('profile_id', axis=1), y_train)\n",
    "end = time.time()\n",
    "\n",
    "preds_RF_val = clf_RF.predict(X_test.drop('profile_id', axis=1))\n",
    "preds_RF_train = clf_RF.predict(X_train.drop('profile_id', axis=1))\n",
    "\n",
    "kappa = cohen_kappa_score(preds_RF_val, y_test)\n",
    "accuracy = accuracy_score(preds_RF_val, y_test)\n",
    "print(f'Kappa: {kappa}, Accuracy: {accuracy}, Time: {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.5145810016275103, Accuracy: 0.5633802816901409, Time: 90.37200999259949\n"
     ]
    }
   ],
   "source": [
    "clf_XGB = XGBClassifier(n_estimators=300, min_child_weight=7,\n",
    "                    gamma=0.2, subsample=0.8, colsample_bytree=0.8, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "clf_XGB.fit(X_train.drop('profile_id', axis=1), y_train)\n",
    "end = time.time()\n",
    "\n",
    "preds_XGB_val = clf_XGB.predict(X_test.drop('profile_id', axis=1))\n",
    "preds_XGB_train = clf_XGB.predict(X_train.drop('profile_id', axis=1))\n",
    "\n",
    "kappa = cohen_kappa_score(preds_XGB_val, y_test)\n",
    "accuracy = accuracy_score(preds_XGB_val, y_test)\n",
    "print(f'Kappa: {kappa}, Accuracy: {accuracy}, Time: {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4855 samples, validate on 540 samples\n",
      "Epoch 1/1500\n",
      "4855/4855 [==============================] - 0s 66us/step - loss: 3.3739 - acc: 0.0371 - val_loss: 3.7053 - val_acc: 0.0315\n",
      "Epoch 2/1500\n",
      "4855/4855 [==============================] - 0s 28us/step - loss: 3.2906 - acc: 0.0501 - val_loss: 3.6585 - val_acc: 0.0481\n",
      "Epoch 3/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 3.2124 - acc: 0.0622 - val_loss: 3.6150 - val_acc: 0.0574\n",
      "Epoch 4/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 3.1391 - acc: 0.0787 - val_loss: 3.5750 - val_acc: 0.0722\n",
      "Epoch 5/1500\n",
      "4855/4855 [==============================] - 0s 28us/step - loss: 3.0702 - acc: 0.0943 - val_loss: 3.5387 - val_acc: 0.0796\n",
      "Epoch 6/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 3.0056 - acc: 0.1085 - val_loss: 3.5048 - val_acc: 0.0907\n",
      "Epoch 7/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 2.9452 - acc: 0.1226 - val_loss: 3.4734 - val_acc: 0.0926\n",
      "Epoch 8/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.8885 - acc: 0.1382 - val_loss: 3.4441 - val_acc: 0.1056\n",
      "Epoch 9/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.8353 - acc: 0.1547 - val_loss: 3.4175 - val_acc: 0.1111\n",
      "Epoch 10/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 2.7853 - acc: 0.1757 - val_loss: 3.3914 - val_acc: 0.1204\n",
      "Epoch 11/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.7383 - acc: 0.1965 - val_loss: 3.3674 - val_acc: 0.1185\n",
      "Epoch 12/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.6940 - acc: 0.2175 - val_loss: 3.3460 - val_acc: 0.1259\n",
      "Epoch 13/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.6524 - acc: 0.2375 - val_loss: 3.3251 - val_acc: 0.1241\n",
      "Epoch 14/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.6134 - acc: 0.2560 - val_loss: 3.3049 - val_acc: 0.1259\n",
      "Epoch 15/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.5767 - acc: 0.2682 - val_loss: 3.2856 - val_acc: 0.1241\n",
      "Epoch 16/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.5420 - acc: 0.2766 - val_loss: 3.2684 - val_acc: 0.1222\n",
      "Epoch 17/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.5095 - acc: 0.2857 - val_loss: 3.2503 - val_acc: 0.1259\n",
      "Epoch 18/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.4787 - acc: 0.2954 - val_loss: 3.2338 - val_acc: 0.1278\n",
      "Epoch 19/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 2.4497 - acc: 0.3013 - val_loss: 3.2177 - val_acc: 0.1278\n",
      "Epoch 20/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 2.4224 - acc: 0.3065 - val_loss: 3.2027 - val_acc: 0.1315\n",
      "Epoch 21/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.3965 - acc: 0.3120 - val_loss: 3.1871 - val_acc: 0.1352\n",
      "Epoch 22/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.3721 - acc: 0.3156 - val_loss: 3.1720 - val_acc: 0.1333\n",
      "Epoch 23/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.3489 - acc: 0.3199 - val_loss: 3.1568 - val_acc: 0.1333\n",
      "Epoch 24/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.3270 - acc: 0.3246 - val_loss: 3.1433 - val_acc: 0.1352\n",
      "Epoch 25/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.3062 - acc: 0.3314 - val_loss: 3.1291 - val_acc: 0.1352\n",
      "Epoch 26/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.2865 - acc: 0.3370 - val_loss: 3.1152 - val_acc: 0.1333\n",
      "Epoch 27/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.2678 - acc: 0.3415 - val_loss: 3.1012 - val_acc: 0.1296\n",
      "Epoch 28/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 2.2499 - acc: 0.3438 - val_loss: 3.0876 - val_acc: 0.1315\n",
      "Epoch 29/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.2330 - acc: 0.3495 - val_loss: 3.0757 - val_acc: 0.1296\n",
      "Epoch 30/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.2167 - acc: 0.3547 - val_loss: 3.0620 - val_acc: 0.1278\n",
      "Epoch 31/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.2012 - acc: 0.3580 - val_loss: 3.0493 - val_acc: 0.1333\n",
      "Epoch 32/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1864 - acc: 0.3633 - val_loss: 3.0359 - val_acc: 0.1315\n",
      "Epoch 33/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1723 - acc: 0.3681 - val_loss: 3.0231 - val_acc: 0.1370\n",
      "Epoch 34/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1588 - acc: 0.3710 - val_loss: 3.0107 - val_acc: 0.1352\n",
      "Epoch 35/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1458 - acc: 0.3730 - val_loss: 2.9971 - val_acc: 0.1352\n",
      "Epoch 36/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1334 - acc: 0.3743 - val_loss: 2.9852 - val_acc: 0.1389\n",
      "Epoch 37/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1214 - acc: 0.3757 - val_loss: 2.9724 - val_acc: 0.1426\n",
      "Epoch 38/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.1100 - acc: 0.3788 - val_loss: 2.9605 - val_acc: 0.1481\n",
      "Epoch 39/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0989 - acc: 0.3813 - val_loss: 2.9485 - val_acc: 0.1519\n",
      "Epoch 40/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0883 - acc: 0.3831 - val_loss: 2.9359 - val_acc: 0.1500\n",
      "Epoch 41/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0781 - acc: 0.3860 - val_loss: 2.9239 - val_acc: 0.1481\n",
      "Epoch 42/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0682 - acc: 0.3874 - val_loss: 2.9117 - val_acc: 0.1500\n",
      "Epoch 43/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 2.0586 - acc: 0.3895 - val_loss: 2.9002 - val_acc: 0.1537\n",
      "Epoch 44/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 2.0494 - acc: 0.3907 - val_loss: 2.8893 - val_acc: 0.1537\n",
      "Epoch 45/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0404 - acc: 0.3928 - val_loss: 2.8784 - val_acc: 0.1537\n",
      "Epoch 46/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0317 - acc: 0.3953 - val_loss: 2.8667 - val_acc: 0.1556\n",
      "Epoch 47/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0233 - acc: 0.3961 - val_loss: 2.8566 - val_acc: 0.1593\n",
      "Epoch 48/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0152 - acc: 0.3988 - val_loss: 2.8454 - val_acc: 0.1611\n",
      "Epoch 49/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 2.0074 - acc: 0.3988 - val_loss: 2.8345 - val_acc: 0.1630\n",
      "Epoch 50/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9997 - acc: 0.4008 - val_loss: 2.8238 - val_acc: 0.1630\n",
      "Epoch 51/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9923 - acc: 0.4025 - val_loss: 2.8138 - val_acc: 0.1667\n",
      "Epoch 52/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9851 - acc: 0.4023 - val_loss: 2.8042 - val_acc: 0.1704\n",
      "Epoch 53/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9780 - acc: 0.4037 - val_loss: 2.7937 - val_acc: 0.1704\n",
      "Epoch 54/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.9712 - acc: 0.4047 - val_loss: 2.7842 - val_acc: 0.1704\n",
      "Epoch 55/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9646 - acc: 0.4054 - val_loss: 2.7759 - val_acc: 0.1704\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9581 - acc: 0.4068 - val_loss: 2.7660 - val_acc: 0.1704\n",
      "Epoch 57/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9518 - acc: 0.4064 - val_loss: 2.7574 - val_acc: 0.1704\n",
      "Epoch 58/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9456 - acc: 0.4074 - val_loss: 2.7492 - val_acc: 0.1722\n",
      "Epoch 59/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9397 - acc: 0.4087 - val_loss: 2.7402 - val_acc: 0.1704\n",
      "Epoch 60/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9338 - acc: 0.4076 - val_loss: 2.7320 - val_acc: 0.1667\n",
      "Epoch 61/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9282 - acc: 0.4089 - val_loss: 2.7238 - val_acc: 0.1722\n",
      "Epoch 62/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9226 - acc: 0.4095 - val_loss: 2.7158 - val_acc: 0.1741\n",
      "Epoch 63/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9172 - acc: 0.4095 - val_loss: 2.7070 - val_acc: 0.1722\n",
      "Epoch 64/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9118 - acc: 0.4109 - val_loss: 2.6996 - val_acc: 0.1741\n",
      "Epoch 65/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9066 - acc: 0.4126 - val_loss: 2.6928 - val_acc: 0.1741\n",
      "Epoch 66/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.9016 - acc: 0.4132 - val_loss: 2.6851 - val_acc: 0.1778\n",
      "Epoch 67/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8967 - acc: 0.4136 - val_loss: 2.6782 - val_acc: 0.1778\n",
      "Epoch 68/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8919 - acc: 0.4159 - val_loss: 2.6715 - val_acc: 0.1778\n",
      "Epoch 69/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.8873 - acc: 0.4161 - val_loss: 2.6644 - val_acc: 0.1815\n",
      "Epoch 70/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.8827 - acc: 0.4152 - val_loss: 2.6587 - val_acc: 0.1852\n",
      "Epoch 71/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.8782 - acc: 0.4161 - val_loss: 2.6511 - val_acc: 0.1870\n",
      "Epoch 72/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8738 - acc: 0.4163 - val_loss: 2.6448 - val_acc: 0.1889\n",
      "Epoch 73/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8695 - acc: 0.4167 - val_loss: 2.6387 - val_acc: 0.1907\n",
      "Epoch 74/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8653 - acc: 0.4183 - val_loss: 2.6306 - val_acc: 0.1944\n",
      "Epoch 75/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8612 - acc: 0.4192 - val_loss: 2.6276 - val_acc: 0.1926\n",
      "Epoch 76/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8572 - acc: 0.4196 - val_loss: 2.6206 - val_acc: 0.1944\n",
      "Epoch 77/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8532 - acc: 0.4202 - val_loss: 2.6138 - val_acc: 0.1981\n",
      "Epoch 78/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8494 - acc: 0.4210 - val_loss: 2.6094 - val_acc: 0.2019\n",
      "Epoch 79/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8456 - acc: 0.4214 - val_loss: 2.6032 - val_acc: 0.2000\n",
      "Epoch 80/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8419 - acc: 0.4231 - val_loss: 2.5987 - val_acc: 0.2000\n",
      "Epoch 81/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.8382 - acc: 0.4235 - val_loss: 2.5926 - val_acc: 0.2019\n",
      "Epoch 82/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.8346 - acc: 0.4241 - val_loss: 2.5884 - val_acc: 0.2000\n",
      "Epoch 83/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8311 - acc: 0.4253 - val_loss: 2.5831 - val_acc: 0.2000\n",
      "Epoch 84/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8277 - acc: 0.4264 - val_loss: 2.5765 - val_acc: 0.2037\n",
      "Epoch 85/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.8243 - acc: 0.4280 - val_loss: 2.5723 - val_acc: 0.2037\n",
      "Epoch 86/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.8209 - acc: 0.4278 - val_loss: 2.5678 - val_acc: 0.2037\n",
      "Epoch 87/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.8177 - acc: 0.4278 - val_loss: 2.5625 - val_acc: 0.2056\n",
      "Epoch 88/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.8144 - acc: 0.4299 - val_loss: 2.5592 - val_acc: 0.2074\n",
      "Epoch 89/1500\n",
      "4855/4855 [==============================] - 0s 30us/step - loss: 1.8113 - acc: 0.4309 - val_loss: 2.5543 - val_acc: 0.2056\n",
      "Epoch 90/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.8082 - acc: 0.4313 - val_loss: 2.5495 - val_acc: 0.2056\n",
      "Epoch 91/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.8052 - acc: 0.4315 - val_loss: 2.5459 - val_acc: 0.2056\n",
      "Epoch 92/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.8022 - acc: 0.4315 - val_loss: 2.5415 - val_acc: 0.2056\n",
      "Epoch 93/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.7993 - acc: 0.4317 - val_loss: 2.5366 - val_acc: 0.2056\n",
      "Epoch 94/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.7964 - acc: 0.4325 - val_loss: 2.5321 - val_acc: 0.2074\n",
      "Epoch 95/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.7936 - acc: 0.4325 - val_loss: 2.5280 - val_acc: 0.2056\n",
      "Epoch 96/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.7908 - acc: 0.4327 - val_loss: 2.5244 - val_acc: 0.2093\n",
      "Epoch 97/1500\n",
      "4855/4855 [==============================] - 0s 28us/step - loss: 1.7881 - acc: 0.4325 - val_loss: 2.5207 - val_acc: 0.2074\n",
      "Epoch 98/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.7853 - acc: 0.4334 - val_loss: 2.5171 - val_acc: 0.2093\n",
      "Epoch 99/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.7827 - acc: 0.4336 - val_loss: 2.5138 - val_acc: 0.2093\n",
      "Epoch 100/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7801 - acc: 0.4342 - val_loss: 2.5090 - val_acc: 0.2111\n",
      "Epoch 101/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7775 - acc: 0.4340 - val_loss: 2.5064 - val_acc: 0.2111\n",
      "Epoch 102/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7750 - acc: 0.4348 - val_loss: 2.5032 - val_acc: 0.2111\n",
      "Epoch 103/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7725 - acc: 0.4354 - val_loss: 2.4997 - val_acc: 0.2111\n",
      "Epoch 104/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7700 - acc: 0.4358 - val_loss: 2.4965 - val_acc: 0.2130\n",
      "Epoch 105/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7675 - acc: 0.4363 - val_loss: 2.4931 - val_acc: 0.2130\n",
      "Epoch 106/1500\n",
      "4855/4855 [==============================] - 0s 22us/step - loss: 1.7651 - acc: 0.4373 - val_loss: 2.4889 - val_acc: 0.2111\n",
      "Epoch 107/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7628 - acc: 0.4377 - val_loss: 2.4864 - val_acc: 0.2130\n",
      "Epoch 108/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7604 - acc: 0.4383 - val_loss: 2.4822 - val_acc: 0.2148\n",
      "Epoch 109/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7581 - acc: 0.4387 - val_loss: 2.4808 - val_acc: 0.2148\n",
      "Epoch 110/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.7559 - acc: 0.4387 - val_loss: 2.4767 - val_acc: 0.2148\n",
      "Epoch 111/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.7537 - acc: 0.4387 - val_loss: 2.4743 - val_acc: 0.2167\n",
      "Epoch 112/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7514 - acc: 0.4385 - val_loss: 2.4708 - val_acc: 0.2185\n",
      "Epoch 113/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7493 - acc: 0.4387 - val_loss: 2.4685 - val_acc: 0.2185\n",
      "Epoch 114/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7471 - acc: 0.4393 - val_loss: 2.4663 - val_acc: 0.2222\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7450 - acc: 0.4404 - val_loss: 2.4642 - val_acc: 0.2241\n",
      "Epoch 116/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7429 - acc: 0.4391 - val_loss: 2.4601 - val_acc: 0.2241\n",
      "Epoch 117/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7408 - acc: 0.4391 - val_loss: 2.4580 - val_acc: 0.2259\n",
      "Epoch 118/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7388 - acc: 0.4400 - val_loss: 2.4555 - val_acc: 0.2259\n",
      "Epoch 119/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7367 - acc: 0.4408 - val_loss: 2.4521 - val_acc: 0.2259\n",
      "Epoch 120/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7348 - acc: 0.4406 - val_loss: 2.4501 - val_acc: 0.2278\n",
      "Epoch 121/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7328 - acc: 0.4408 - val_loss: 2.4483 - val_acc: 0.2259\n",
      "Epoch 122/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7309 - acc: 0.4416 - val_loss: 2.4448 - val_acc: 0.2259\n",
      "Epoch 123/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7290 - acc: 0.4408 - val_loss: 2.4427 - val_acc: 0.2259\n",
      "Epoch 124/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7271 - acc: 0.4412 - val_loss: 2.4400 - val_acc: 0.2259\n",
      "Epoch 125/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7252 - acc: 0.4418 - val_loss: 2.4386 - val_acc: 0.2259\n",
      "Epoch 126/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7234 - acc: 0.4414 - val_loss: 2.4355 - val_acc: 0.2259\n",
      "Epoch 127/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7216 - acc: 0.4416 - val_loss: 2.4334 - val_acc: 0.2278\n",
      "Epoch 128/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7198 - acc: 0.4420 - val_loss: 2.4317 - val_acc: 0.2278\n",
      "Epoch 129/1500\n",
      "4855/4855 [==============================] - 0s 28us/step - loss: 1.7181 - acc: 0.4426 - val_loss: 2.4293 - val_acc: 0.2278\n",
      "Epoch 130/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.7163 - acc: 0.4426 - val_loss: 2.4271 - val_acc: 0.2278\n",
      "Epoch 131/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7146 - acc: 0.4420 - val_loss: 2.4252 - val_acc: 0.2278\n",
      "Epoch 132/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7129 - acc: 0.4426 - val_loss: 2.4241 - val_acc: 0.2278\n",
      "Epoch 133/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7112 - acc: 0.4428 - val_loss: 2.4217 - val_acc: 0.2296\n",
      "Epoch 134/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7096 - acc: 0.4424 - val_loss: 2.4195 - val_acc: 0.2296\n",
      "Epoch 135/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7079 - acc: 0.4426 - val_loss: 2.4173 - val_acc: 0.2315\n",
      "Epoch 136/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7063 - acc: 0.4424 - val_loss: 2.4153 - val_acc: 0.2315\n",
      "Epoch 137/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.7047 - acc: 0.4426 - val_loss: 2.4138 - val_acc: 0.2315\n",
      "Epoch 138/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7031 - acc: 0.4426 - val_loss: 2.4133 - val_acc: 0.2315\n",
      "Epoch 139/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7015 - acc: 0.4428 - val_loss: 2.4109 - val_acc: 0.2315\n",
      "Epoch 140/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.7000 - acc: 0.4428 - val_loss: 2.4098 - val_acc: 0.2315\n",
      "Epoch 141/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6984 - acc: 0.4437 - val_loss: 2.4069 - val_acc: 0.2296\n",
      "Epoch 142/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6969 - acc: 0.4437 - val_loss: 2.4044 - val_acc: 0.2315\n",
      "Epoch 143/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.6953 - acc: 0.4439 - val_loss: 2.4033 - val_acc: 0.2315\n",
      "Epoch 144/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6939 - acc: 0.4439 - val_loss: 2.4018 - val_acc: 0.2315\n",
      "Epoch 145/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6924 - acc: 0.4445 - val_loss: 2.4002 - val_acc: 0.2315\n",
      "Epoch 146/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6909 - acc: 0.4443 - val_loss: 2.3974 - val_acc: 0.2315\n",
      "Epoch 147/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.6894 - acc: 0.4445 - val_loss: 2.3974 - val_acc: 0.2315\n",
      "Epoch 148/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.6880 - acc: 0.4445 - val_loss: 2.3950 - val_acc: 0.2315\n",
      "Epoch 149/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6866 - acc: 0.4449 - val_loss: 2.3945 - val_acc: 0.2315\n",
      "Epoch 150/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6852 - acc: 0.4459 - val_loss: 2.3931 - val_acc: 0.2315\n",
      "Epoch 151/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6838 - acc: 0.4455 - val_loss: 2.3912 - val_acc: 0.2333\n",
      "Epoch 152/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6824 - acc: 0.4457 - val_loss: 2.3889 - val_acc: 0.2333\n",
      "Epoch 153/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6810 - acc: 0.4461 - val_loss: 2.3884 - val_acc: 0.2296\n",
      "Epoch 154/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6797 - acc: 0.4457 - val_loss: 2.3864 - val_acc: 0.2315\n",
      "Epoch 155/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6783 - acc: 0.4461 - val_loss: 2.3852 - val_acc: 0.2333\n",
      "Epoch 156/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6770 - acc: 0.4459 - val_loss: 2.3834 - val_acc: 0.2333\n",
      "Epoch 157/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6757 - acc: 0.4472 - val_loss: 2.3832 - val_acc: 0.2315\n",
      "Epoch 158/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.6744 - acc: 0.4474 - val_loss: 2.3805 - val_acc: 0.2315\n",
      "Epoch 159/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.6731 - acc: 0.4474 - val_loss: 2.3796 - val_acc: 0.2315\n",
      "Epoch 160/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.6719 - acc: 0.4488 - val_loss: 2.3772 - val_acc: 0.2315\n",
      "Epoch 161/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.6706 - acc: 0.4490 - val_loss: 2.3769 - val_acc: 0.2333\n",
      "Epoch 162/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6693 - acc: 0.4496 - val_loss: 2.3759 - val_acc: 0.2333\n",
      "Epoch 163/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6681 - acc: 0.4494 - val_loss: 2.3750 - val_acc: 0.2333\n",
      "Epoch 164/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6669 - acc: 0.4496 - val_loss: 2.3740 - val_acc: 0.2333\n",
      "Epoch 165/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6657 - acc: 0.4501 - val_loss: 2.3723 - val_acc: 0.2370\n",
      "Epoch 166/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6645 - acc: 0.4498 - val_loss: 2.3717 - val_acc: 0.2370\n",
      "Epoch 167/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6633 - acc: 0.4503 - val_loss: 2.3709 - val_acc: 0.2370\n",
      "Epoch 168/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6621 - acc: 0.4509 - val_loss: 2.3686 - val_acc: 0.2370\n",
      "Epoch 169/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6609 - acc: 0.4509 - val_loss: 2.3688 - val_acc: 0.2370\n",
      "Epoch 170/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6598 - acc: 0.4515 - val_loss: 2.3668 - val_acc: 0.2370\n",
      "Epoch 171/1500\n",
      "4855/4855 [==============================] - 0s 28us/step - loss: 1.6586 - acc: 0.4511 - val_loss: 2.3660 - val_acc: 0.2370\n",
      "Epoch 172/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6574 - acc: 0.4517 - val_loss: 2.3649 - val_acc: 0.2370\n",
      "Epoch 173/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.6563 - acc: 0.4517 - val_loss: 2.3640 - val_acc: 0.2370\n",
      "Epoch 174/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6552 - acc: 0.4521 - val_loss: 2.3633 - val_acc: 0.2370\n",
      "Epoch 175/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6540 - acc: 0.4527 - val_loss: 2.3621 - val_acc: 0.2352\n",
      "Epoch 176/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6529 - acc: 0.4521 - val_loss: 2.3603 - val_acc: 0.2352\n",
      "Epoch 177/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6518 - acc: 0.4523 - val_loss: 2.3594 - val_acc: 0.2352\n",
      "Epoch 178/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6507 - acc: 0.4536 - val_loss: 2.3583 - val_acc: 0.2352\n",
      "Epoch 179/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6496 - acc: 0.4540 - val_loss: 2.3581 - val_acc: 0.2370\n",
      "Epoch 180/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6486 - acc: 0.4538 - val_loss: 2.3567 - val_acc: 0.2370\n",
      "Epoch 181/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6475 - acc: 0.4550 - val_loss: 2.3556 - val_acc: 0.2370\n",
      "Epoch 182/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6464 - acc: 0.4548 - val_loss: 2.3534 - val_acc: 0.2370\n",
      "Epoch 183/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6454 - acc: 0.4550 - val_loss: 2.3527 - val_acc: 0.2370\n",
      "Epoch 184/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6443 - acc: 0.4550 - val_loss: 2.3522 - val_acc: 0.2389\n",
      "Epoch 185/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6433 - acc: 0.4556 - val_loss: 2.3516 - val_acc: 0.2389\n",
      "Epoch 186/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6423 - acc: 0.4564 - val_loss: 2.3499 - val_acc: 0.2389\n",
      "Epoch 187/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6412 - acc: 0.4571 - val_loss: 2.3499 - val_acc: 0.2389\n",
      "Epoch 188/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6402 - acc: 0.4558 - val_loss: 2.3482 - val_acc: 0.2389\n",
      "Epoch 189/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6392 - acc: 0.4568 - val_loss: 2.3481 - val_acc: 0.2389\n",
      "Epoch 190/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6382 - acc: 0.4566 - val_loss: 2.3477 - val_acc: 0.2389\n",
      "Epoch 191/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6372 - acc: 0.4560 - val_loss: 2.3460 - val_acc: 0.2389\n",
      "Epoch 192/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6363 - acc: 0.4575 - val_loss: 2.3456 - val_acc: 0.2389\n",
      "Epoch 193/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6353 - acc: 0.4577 - val_loss: 2.3448 - val_acc: 0.2389\n",
      "Epoch 194/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6343 - acc: 0.4573 - val_loss: 2.3442 - val_acc: 0.2389\n",
      "Epoch 195/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6334 - acc: 0.4579 - val_loss: 2.3442 - val_acc: 0.2370\n",
      "Epoch 196/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.6324 - acc: 0.4579 - val_loss: 2.3421 - val_acc: 0.2370\n",
      "Epoch 197/1500\n",
      "4855/4855 [==============================] - 0s 26us/step - loss: 1.6315 - acc: 0.4585 - val_loss: 2.3407 - val_acc: 0.2370\n",
      "Epoch 198/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6305 - acc: 0.4577 - val_loss: 2.3406 - val_acc: 0.2370\n",
      "Epoch 199/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6296 - acc: 0.4579 - val_loss: 2.3401 - val_acc: 0.2370\n",
      "Epoch 200/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6286 - acc: 0.4583 - val_loss: 2.3402 - val_acc: 0.2352\n",
      "Epoch 201/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6277 - acc: 0.4583 - val_loss: 2.3389 - val_acc: 0.2370\n",
      "Epoch 202/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6268 - acc: 0.4591 - val_loss: 2.3380 - val_acc: 0.2352\n",
      "Epoch 203/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6259 - acc: 0.4597 - val_loss: 2.3375 - val_acc: 0.2352\n",
      "Epoch 204/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6250 - acc: 0.4589 - val_loss: 2.3372 - val_acc: 0.2352\n",
      "Epoch 205/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6241 - acc: 0.4593 - val_loss: 2.3362 - val_acc: 0.2352\n",
      "Epoch 206/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6232 - acc: 0.4591 - val_loss: 2.3373 - val_acc: 0.2352\n",
      "Epoch 207/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6223 - acc: 0.4599 - val_loss: 2.3350 - val_acc: 0.2352\n",
      "Epoch 208/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6215 - acc: 0.4593 - val_loss: 2.3349 - val_acc: 0.2352\n",
      "Epoch 209/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6206 - acc: 0.4595 - val_loss: 2.3341 - val_acc: 0.2352\n",
      "Epoch 210/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6198 - acc: 0.4599 - val_loss: 2.3328 - val_acc: 0.2352\n",
      "Epoch 211/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6189 - acc: 0.4604 - val_loss: 2.3322 - val_acc: 0.2352\n",
      "Epoch 212/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6181 - acc: 0.4608 - val_loss: 2.3318 - val_acc: 0.2352\n",
      "Epoch 213/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6172 - acc: 0.4601 - val_loss: 2.3318 - val_acc: 0.2333\n",
      "Epoch 214/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6164 - acc: 0.4612 - val_loss: 2.3309 - val_acc: 0.2333\n",
      "Epoch 215/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6155 - acc: 0.4610 - val_loss: 2.3299 - val_acc: 0.2352\n",
      "Epoch 216/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6147 - acc: 0.4614 - val_loss: 2.3296 - val_acc: 0.2333\n",
      "Epoch 217/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6139 - acc: 0.4620 - val_loss: 2.3281 - val_acc: 0.2352\n",
      "Epoch 218/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6131 - acc: 0.4618 - val_loss: 2.3286 - val_acc: 0.2370\n",
      "Epoch 219/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6123 - acc: 0.4624 - val_loss: 2.3287 - val_acc: 0.2370\n",
      "Epoch 220/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6114 - acc: 0.4628 - val_loss: 2.3268 - val_acc: 0.2370\n",
      "Epoch 221/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.6106 - acc: 0.4626 - val_loss: 2.3263 - val_acc: 0.2352\n",
      "Epoch 222/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6098 - acc: 0.4632 - val_loss: 2.3251 - val_acc: 0.2352\n",
      "Epoch 223/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6090 - acc: 0.4645 - val_loss: 2.3246 - val_acc: 0.2352\n",
      "Epoch 224/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6082 - acc: 0.4645 - val_loss: 2.3248 - val_acc: 0.2352\n",
      "Epoch 225/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6074 - acc: 0.4643 - val_loss: 2.3244 - val_acc: 0.2370\n",
      "Epoch 226/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6066 - acc: 0.4643 - val_loss: 2.3230 - val_acc: 0.2370\n",
      "Epoch 227/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6058 - acc: 0.4643 - val_loss: 2.3229 - val_acc: 0.2352\n",
      "Epoch 228/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6050 - acc: 0.4643 - val_loss: 2.3227 - val_acc: 0.2352\n",
      "Epoch 229/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6043 - acc: 0.4641 - val_loss: 2.3221 - val_acc: 0.2352\n",
      "Epoch 230/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6035 - acc: 0.4651 - val_loss: 2.3221 - val_acc: 0.2352\n",
      "Epoch 231/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6027 - acc: 0.4657 - val_loss: 2.3202 - val_acc: 0.2370\n",
      "Epoch 232/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6020 - acc: 0.4657 - val_loss: 2.3192 - val_acc: 0.2370\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6012 - acc: 0.4659 - val_loss: 2.3195 - val_acc: 0.2370\n",
      "Epoch 234/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.6005 - acc: 0.4659 - val_loss: 2.3198 - val_acc: 0.2370\n",
      "Epoch 235/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5997 - acc: 0.4659 - val_loss: 2.3189 - val_acc: 0.2370\n",
      "Epoch 236/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5990 - acc: 0.4665 - val_loss: 2.3180 - val_acc: 0.2370\n",
      "Epoch 237/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5982 - acc: 0.4674 - val_loss: 2.3186 - val_acc: 0.2370\n",
      "Epoch 238/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5976 - acc: 0.4667 - val_loss: 2.3179 - val_acc: 0.2370\n",
      "Epoch 239/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5968 - acc: 0.4678 - val_loss: 2.3176 - val_acc: 0.2352\n",
      "Epoch 240/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5960 - acc: 0.4676 - val_loss: 2.3159 - val_acc: 0.2370\n",
      "Epoch 241/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5953 - acc: 0.4680 - val_loss: 2.3162 - val_acc: 0.2370\n",
      "Epoch 242/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5946 - acc: 0.4682 - val_loss: 2.3152 - val_acc: 0.2370\n",
      "Epoch 243/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5939 - acc: 0.4686 - val_loss: 2.3151 - val_acc: 0.2370\n",
      "Epoch 244/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5932 - acc: 0.4674 - val_loss: 2.3153 - val_acc: 0.2370\n",
      "Epoch 245/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5924 - acc: 0.4684 - val_loss: 2.3137 - val_acc: 0.2389\n",
      "Epoch 246/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5917 - acc: 0.4682 - val_loss: 2.3130 - val_acc: 0.2389\n",
      "Epoch 247/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5911 - acc: 0.4688 - val_loss: 2.3121 - val_acc: 0.2407\n",
      "Epoch 248/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5903 - acc: 0.4686 - val_loss: 2.3119 - val_acc: 0.2407\n",
      "Epoch 249/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5896 - acc: 0.4692 - val_loss: 2.3121 - val_acc: 0.2407\n",
      "Epoch 250/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5890 - acc: 0.4688 - val_loss: 2.3122 - val_acc: 0.2407\n",
      "Epoch 251/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5883 - acc: 0.4700 - val_loss: 2.3113 - val_acc: 0.2407\n",
      "Epoch 252/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5876 - acc: 0.4696 - val_loss: 2.3110 - val_acc: 0.2407\n",
      "Epoch 253/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5869 - acc: 0.4692 - val_loss: 2.3089 - val_acc: 0.2407\n",
      "Epoch 254/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5862 - acc: 0.4696 - val_loss: 2.3107 - val_acc: 0.2407\n",
      "Epoch 255/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5855 - acc: 0.4700 - val_loss: 2.3087 - val_acc: 0.2426\n",
      "Epoch 256/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5849 - acc: 0.4713 - val_loss: 2.3082 - val_acc: 0.2426\n",
      "Epoch 257/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5842 - acc: 0.4704 - val_loss: 2.3080 - val_acc: 0.2426\n",
      "Epoch 258/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5836 - acc: 0.4702 - val_loss: 2.3066 - val_acc: 0.2426\n",
      "Epoch 259/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5829 - acc: 0.4711 - val_loss: 2.3063 - val_acc: 0.2426\n",
      "Epoch 260/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5822 - acc: 0.4711 - val_loss: 2.3072 - val_acc: 0.2407\n",
      "Epoch 261/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5815 - acc: 0.4721 - val_loss: 2.3063 - val_acc: 0.2426\n",
      "Epoch 262/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5809 - acc: 0.4723 - val_loss: 2.3059 - val_acc: 0.2426\n",
      "Epoch 263/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5802 - acc: 0.4717 - val_loss: 2.3047 - val_acc: 0.2426\n",
      "Epoch 264/1500\n",
      "4855/4855 [==============================] - 0s 25us/step - loss: 1.5796 - acc: 0.4719 - val_loss: 2.3047 - val_acc: 0.2444\n",
      "Epoch 265/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5789 - acc: 0.4719 - val_loss: 2.3045 - val_acc: 0.2426\n",
      "Epoch 266/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5783 - acc: 0.4719 - val_loss: 2.3045 - val_acc: 0.2444\n",
      "Epoch 267/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5776 - acc: 0.4719 - val_loss: 2.3042 - val_acc: 0.2444\n",
      "Epoch 268/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5771 - acc: 0.4719 - val_loss: 2.3032 - val_acc: 0.2444\n",
      "Epoch 269/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5764 - acc: 0.4719 - val_loss: 2.3025 - val_acc: 0.2444\n",
      "Epoch 270/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5758 - acc: 0.4717 - val_loss: 2.3023 - val_acc: 0.2444\n",
      "Epoch 271/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5751 - acc: 0.4729 - val_loss: 2.3020 - val_acc: 0.2444\n",
      "Epoch 272/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5745 - acc: 0.4723 - val_loss: 2.3017 - val_acc: 0.2444\n",
      "Epoch 273/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5739 - acc: 0.4729 - val_loss: 2.3011 - val_acc: 0.2444\n",
      "Epoch 274/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5733 - acc: 0.4731 - val_loss: 2.3011 - val_acc: 0.2444\n",
      "Epoch 275/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5726 - acc: 0.4733 - val_loss: 2.3005 - val_acc: 0.2426\n",
      "Epoch 276/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5721 - acc: 0.4739 - val_loss: 2.2992 - val_acc: 0.2426\n",
      "Epoch 277/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5714 - acc: 0.4742 - val_loss: 2.2994 - val_acc: 0.2426\n",
      "Epoch 278/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5708 - acc: 0.4746 - val_loss: 2.2996 - val_acc: 0.2426\n",
      "Epoch 279/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5702 - acc: 0.4742 - val_loss: 2.2992 - val_acc: 0.2426\n",
      "Epoch 280/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5696 - acc: 0.4748 - val_loss: 2.2985 - val_acc: 0.2426\n",
      "Epoch 281/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5691 - acc: 0.4756 - val_loss: 2.2966 - val_acc: 0.2444\n",
      "Epoch 282/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5684 - acc: 0.4754 - val_loss: 2.2970 - val_acc: 0.2444\n",
      "Epoch 283/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5678 - acc: 0.4754 - val_loss: 2.2972 - val_acc: 0.2444\n",
      "Epoch 284/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5673 - acc: 0.4758 - val_loss: 2.2959 - val_acc: 0.2444\n",
      "Epoch 285/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5667 - acc: 0.4750 - val_loss: 2.2966 - val_acc: 0.2444\n",
      "Epoch 286/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5661 - acc: 0.4758 - val_loss: 2.2963 - val_acc: 0.2444\n",
      "Epoch 287/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5655 - acc: 0.4760 - val_loss: 2.2959 - val_acc: 0.2444\n",
      "Epoch 288/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5650 - acc: 0.4752 - val_loss: 2.2965 - val_acc: 0.2444\n",
      "Epoch 289/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5644 - acc: 0.4762 - val_loss: 2.2950 - val_acc: 0.2444\n",
      "Epoch 290/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5638 - acc: 0.4762 - val_loss: 2.2949 - val_acc: 0.2444\n",
      "Epoch 291/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5633 - acc: 0.4752 - val_loss: 2.2943 - val_acc: 0.2463\n",
      "Epoch 292/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5627 - acc: 0.4768 - val_loss: 2.2936 - val_acc: 0.2463\n",
      "Epoch 293/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5621 - acc: 0.4762 - val_loss: 2.2935 - val_acc: 0.2463\n",
      "Epoch 294/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5616 - acc: 0.4764 - val_loss: 2.2924 - val_acc: 0.2463\n",
      "Epoch 295/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5610 - acc: 0.4770 - val_loss: 2.2935 - val_acc: 0.2463\n",
      "Epoch 296/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5605 - acc: 0.4770 - val_loss: 2.2933 - val_acc: 0.2463\n",
      "Epoch 297/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5600 - acc: 0.4774 - val_loss: 2.2921 - val_acc: 0.2463\n",
      "Epoch 298/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5594 - acc: 0.4764 - val_loss: 2.2911 - val_acc: 0.2463\n",
      "Epoch 299/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5589 - acc: 0.4772 - val_loss: 2.2917 - val_acc: 0.2463\n",
      "Epoch 300/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5583 - acc: 0.4772 - val_loss: 2.2904 - val_acc: 0.2463\n",
      "Epoch 301/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5578 - acc: 0.4774 - val_loss: 2.2910 - val_acc: 0.2444\n",
      "Epoch 302/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5572 - acc: 0.4777 - val_loss: 2.2908 - val_acc: 0.2444\n",
      "Epoch 303/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5567 - acc: 0.4774 - val_loss: 2.2896 - val_acc: 0.2444\n",
      "Epoch 304/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5561 - acc: 0.4781 - val_loss: 2.2893 - val_acc: 0.2444\n",
      "Epoch 305/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5556 - acc: 0.4785 - val_loss: 2.2900 - val_acc: 0.2444\n",
      "Epoch 306/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5551 - acc: 0.4785 - val_loss: 2.2883 - val_acc: 0.2444\n",
      "Epoch 307/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5546 - acc: 0.4787 - val_loss: 2.2876 - val_acc: 0.2444\n",
      "Epoch 308/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5540 - acc: 0.4783 - val_loss: 2.2877 - val_acc: 0.2444\n",
      "Epoch 309/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5535 - acc: 0.4787 - val_loss: 2.2892 - val_acc: 0.2444\n",
      "Epoch 310/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5530 - acc: 0.4783 - val_loss: 2.2878 - val_acc: 0.2444\n",
      "Epoch 311/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5525 - acc: 0.4791 - val_loss: 2.2865 - val_acc: 0.2463\n",
      "Epoch 312/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5520 - acc: 0.4787 - val_loss: 2.2856 - val_acc: 0.2463\n",
      "Epoch 313/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5514 - acc: 0.4787 - val_loss: 2.2869 - val_acc: 0.2463\n",
      "Epoch 314/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5509 - acc: 0.4783 - val_loss: 2.2874 - val_acc: 0.2463\n",
      "Epoch 315/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5504 - acc: 0.4793 - val_loss: 2.2848 - val_acc: 0.2463\n",
      "Epoch 316/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5499 - acc: 0.4789 - val_loss: 2.2868 - val_acc: 0.2444\n",
      "Epoch 317/1500\n",
      "4855/4855 [==============================] - 0s 27us/step - loss: 1.5495 - acc: 0.4793 - val_loss: 2.2859 - val_acc: 0.2463\n",
      "Epoch 318/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5489 - acc: 0.4787 - val_loss: 2.2843 - val_acc: 0.2481\n",
      "Epoch 319/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5484 - acc: 0.4789 - val_loss: 2.2861 - val_acc: 0.2463\n",
      "Epoch 320/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5479 - acc: 0.4793 - val_loss: 2.2850 - val_acc: 0.2463\n",
      "Epoch 321/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5474 - acc: 0.4791 - val_loss: 2.2846 - val_acc: 0.2463\n",
      "Epoch 322/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5469 - acc: 0.4795 - val_loss: 2.2846 - val_acc: 0.2463\n",
      "Epoch 323/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5465 - acc: 0.4795 - val_loss: 2.2835 - val_acc: 0.2463\n",
      "Epoch 324/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5460 - acc: 0.4793 - val_loss: 2.2828 - val_acc: 0.2463\n",
      "Epoch 325/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5455 - acc: 0.4799 - val_loss: 2.2830 - val_acc: 0.2444\n",
      "Epoch 326/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5450 - acc: 0.4807 - val_loss: 2.2837 - val_acc: 0.2444\n",
      "Epoch 327/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5445 - acc: 0.4807 - val_loss: 2.2823 - val_acc: 0.2444\n",
      "Epoch 328/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5440 - acc: 0.4799 - val_loss: 2.2821 - val_acc: 0.2444\n",
      "Epoch 329/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5435 - acc: 0.4803 - val_loss: 2.2828 - val_acc: 0.2444\n",
      "Epoch 330/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5431 - acc: 0.4816 - val_loss: 2.2813 - val_acc: 0.2444\n",
      "Epoch 331/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5426 - acc: 0.4809 - val_loss: 2.2815 - val_acc: 0.2426\n",
      "Epoch 332/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5421 - acc: 0.4807 - val_loss: 2.2815 - val_acc: 0.2444\n",
      "Epoch 333/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5416 - acc: 0.4807 - val_loss: 2.2799 - val_acc: 0.2444\n",
      "Epoch 334/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5412 - acc: 0.4820 - val_loss: 2.2803 - val_acc: 0.2444\n",
      "Epoch 335/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5407 - acc: 0.4809 - val_loss: 2.2812 - val_acc: 0.2444\n",
      "Epoch 336/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5402 - acc: 0.4812 - val_loss: 2.2794 - val_acc: 0.2444\n",
      "Epoch 337/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5397 - acc: 0.4809 - val_loss: 2.2799 - val_acc: 0.2444\n",
      "Epoch 338/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5393 - acc: 0.4818 - val_loss: 2.2787 - val_acc: 0.2444\n",
      "Epoch 339/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5388 - acc: 0.4816 - val_loss: 2.2794 - val_acc: 0.2444\n",
      "Epoch 340/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5383 - acc: 0.4818 - val_loss: 2.2786 - val_acc: 0.2444\n",
      "Epoch 341/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5379 - acc: 0.4824 - val_loss: 2.2782 - val_acc: 0.2444\n",
      "Epoch 342/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5374 - acc: 0.4822 - val_loss: 2.2771 - val_acc: 0.2444\n",
      "Epoch 343/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5369 - acc: 0.4822 - val_loss: 2.2780 - val_acc: 0.2444\n",
      "Epoch 344/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5365 - acc: 0.4832 - val_loss: 2.2777 - val_acc: 0.2444\n",
      "Epoch 345/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5360 - acc: 0.4824 - val_loss: 2.2769 - val_acc: 0.2444\n",
      "Epoch 346/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5355 - acc: 0.4826 - val_loss: 2.2770 - val_acc: 0.2463\n",
      "Epoch 347/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5351 - acc: 0.4826 - val_loss: 2.2757 - val_acc: 0.2463\n",
      "Epoch 348/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5346 - acc: 0.4828 - val_loss: 2.2754 - val_acc: 0.2463\n",
      "Epoch 349/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5342 - acc: 0.4830 - val_loss: 2.2752 - val_acc: 0.2463\n",
      "Epoch 350/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5337 - acc: 0.4836 - val_loss: 2.2756 - val_acc: 0.2463\n",
      "Epoch 351/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5333 - acc: 0.4830 - val_loss: 2.2750 - val_acc: 0.2463\n",
      "Epoch 352/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5328 - acc: 0.4849 - val_loss: 2.2743 - val_acc: 0.2463\n",
      "Epoch 353/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5324 - acc: 0.4840 - val_loss: 2.2743 - val_acc: 0.2463\n",
      "Epoch 354/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5320 - acc: 0.4836 - val_loss: 2.2739 - val_acc: 0.2463\n",
      "Epoch 355/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5315 - acc: 0.4836 - val_loss: 2.2748 - val_acc: 0.2463\n",
      "Epoch 356/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5311 - acc: 0.4853 - val_loss: 2.2738 - val_acc: 0.2463\n",
      "Epoch 357/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5306 - acc: 0.4849 - val_loss: 2.2734 - val_acc: 0.2463\n",
      "Epoch 358/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5302 - acc: 0.4834 - val_loss: 2.2724 - val_acc: 0.2463\n",
      "Epoch 359/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5297 - acc: 0.4855 - val_loss: 2.2728 - val_acc: 0.2481\n",
      "Epoch 360/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5293 - acc: 0.4853 - val_loss: 2.2736 - val_acc: 0.2463\n",
      "Epoch 361/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5289 - acc: 0.4836 - val_loss: 2.2726 - val_acc: 0.2481\n",
      "Epoch 362/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5285 - acc: 0.4857 - val_loss: 2.2735 - val_acc: 0.2481\n",
      "Epoch 363/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5280 - acc: 0.4847 - val_loss: 2.2714 - val_acc: 0.2481\n",
      "Epoch 364/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5276 - acc: 0.4855 - val_loss: 2.2712 - val_acc: 0.2481\n",
      "Epoch 365/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5272 - acc: 0.4863 - val_loss: 2.2715 - val_acc: 0.2481\n",
      "Epoch 366/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5267 - acc: 0.4849 - val_loss: 2.2713 - val_acc: 0.2481\n",
      "Epoch 367/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5263 - acc: 0.4857 - val_loss: 2.2707 - val_acc: 0.2481\n",
      "Epoch 368/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5259 - acc: 0.4857 - val_loss: 2.2714 - val_acc: 0.2481\n",
      "Epoch 369/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5255 - acc: 0.4855 - val_loss: 2.2708 - val_acc: 0.2481\n",
      "Epoch 370/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5251 - acc: 0.4855 - val_loss: 2.2705 - val_acc: 0.2481\n",
      "Epoch 371/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5246 - acc: 0.4867 - val_loss: 2.2691 - val_acc: 0.2481\n",
      "Epoch 372/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5242 - acc: 0.4857 - val_loss: 2.2702 - val_acc: 0.2463\n",
      "Epoch 373/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5238 - acc: 0.4853 - val_loss: 2.2697 - val_acc: 0.2463\n",
      "Epoch 374/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5234 - acc: 0.4857 - val_loss: 2.2691 - val_acc: 0.2481\n",
      "Epoch 375/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5230 - acc: 0.4857 - val_loss: 2.2685 - val_acc: 0.2463\n",
      "Epoch 376/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5225 - acc: 0.4863 - val_loss: 2.2688 - val_acc: 0.2481\n",
      "Epoch 377/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5222 - acc: 0.4857 - val_loss: 2.2683 - val_acc: 0.2481\n",
      "Epoch 378/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5218 - acc: 0.4863 - val_loss: 2.2684 - val_acc: 0.2463\n",
      "Epoch 379/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5214 - acc: 0.4851 - val_loss: 2.2691 - val_acc: 0.2481\n",
      "Epoch 380/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5209 - acc: 0.4861 - val_loss: 2.2675 - val_acc: 0.2481\n",
      "Epoch 381/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5206 - acc: 0.4867 - val_loss: 2.2671 - val_acc: 0.2481\n",
      "Epoch 382/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5202 - acc: 0.4865 - val_loss: 2.2674 - val_acc: 0.2481\n",
      "Epoch 383/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5198 - acc: 0.4865 - val_loss: 2.2652 - val_acc: 0.2481\n",
      "Epoch 384/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5194 - acc: 0.4871 - val_loss: 2.2667 - val_acc: 0.2481\n",
      "Epoch 385/1500\n",
      "4855/4855 [==============================] - 0s 24us/step - loss: 1.5190 - acc: 0.4867 - val_loss: 2.2660 - val_acc: 0.2481\n",
      "Epoch 386/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5186 - acc: 0.4867 - val_loss: 2.2666 - val_acc: 0.2481\n",
      "Epoch 387/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5183 - acc: 0.4882 - val_loss: 2.2655 - val_acc: 0.2481\n",
      "Epoch 388/1500\n",
      "4855/4855 [==============================] - 0s 23us/step - loss: 1.5178 - acc: 0.4863 - val_loss: 2.2654 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "def create_model_linear(layer_data, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation=\"relu\",\n",
    "                    input_shape=(layer_data.shape[1:])))\n",
    "\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    opt = Adam(lr=0.00001, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "model = create_model_linear(X_train_seq.drop('profile_id', axis=1), y_train_seq.shape[1])\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(X_train_seq.drop('profile_id', axis=1),\n",
    "                    y_train_seq, epochs=1500, validation_split=0.1, callbacks=[es])\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.38748878703350986, Accuracy: 0.45218680504077097, Time: 44.6206169128418\n"
     ]
    }
   ],
   "source": [
    "plot_loss(history)\n",
    "plot_accuracy(history)\n",
    "\n",
    "preds_DNN_val = model.predict(X_test_seq.drop('profile_id', axis=1))\n",
    "preds_DNN_train = model.predict(X_train_seq.drop('profile_id', axis=1))\n",
    "\n",
    "kappa = cohen_kappa_score(y_test_seq.argmax(axis=1), preds_DNN_val.argmax(axis=1))\n",
    "accuracy = accuracy_score(y_test_seq.argmax(axis=1), preds_DNN_val.argmax(axis=1))\n",
    "print(f'Kappa: {kappa}, Accuracy: {accuracy}, Time: {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 4855 samples, validate on 540 samples\n",
      "Epoch 1/500\n",
      "4855/4855 [==============================] - 6s 1ms/step - loss: 2.8886 - acc: 0.1670 - val_loss: 2.8894 - val_acc: 0.1407\n",
      "Epoch 2/500\n",
      "4855/4855 [==============================] - 3s 614us/step - loss: 2.4026 - acc: 0.2737 - val_loss: 2.9939 - val_acc: 0.0870\n",
      "Epoch 3/500\n",
      "4855/4855 [==============================] - 3s 577us/step - loss: 2.2314 - acc: 0.3298 - val_loss: 2.9979 - val_acc: 0.0630\n",
      "Epoch 4/500\n",
      "4855/4855 [==============================] - 3s 589us/step - loss: 2.1373 - acc: 0.3600 - val_loss: 2.8850 - val_acc: 0.1333\n",
      "Epoch 5/500\n",
      "4855/4855 [==============================] - 3s 713us/step - loss: 2.0667 - acc: 0.3740 - val_loss: 2.8607 - val_acc: 0.1333\n",
      "Epoch 6/500\n",
      "4855/4855 [==============================] - 4s 836us/step - loss: 2.0124 - acc: 0.3870 - val_loss: 2.9303 - val_acc: 0.1241\n",
      "Epoch 7/500\n",
      "4855/4855 [==============================] - 4s 883us/step - loss: 1.9697 - acc: 0.3975 - val_loss: 2.7490 - val_acc: 0.1463\n",
      "Epoch 8/500\n",
      "4855/4855 [==============================] - 4s 852us/step - loss: 1.9221 - acc: 0.4056 - val_loss: 2.7498 - val_acc: 0.1241\n",
      "Epoch 9/500\n",
      "4855/4855 [==============================] - 4s 740us/step - loss: 1.8724 - acc: 0.4177 - val_loss: 2.5898 - val_acc: 0.1407\n",
      "Epoch 10/500\n",
      "4855/4855 [==============================] - 3s 679us/step - loss: 1.8336 - acc: 0.4245 - val_loss: 2.5549 - val_acc: 0.1611\n",
      "Epoch 11/500\n",
      "4855/4855 [==============================] - 3s 656us/step - loss: 1.8022 - acc: 0.4292 - val_loss: 2.4325 - val_acc: 0.1944\n",
      "Epoch 12/500\n",
      "4855/4855 [==============================] - 3s 645us/step - loss: 1.7753 - acc: 0.4363 - val_loss: 2.3847 - val_acc: 0.2259\n",
      "Epoch 13/500\n",
      "4855/4855 [==============================] - 3s 663us/step - loss: 1.7561 - acc: 0.4406 - val_loss: 2.4075 - val_acc: 0.2370\n",
      "Epoch 14/500\n",
      "4855/4855 [==============================] - 3s 706us/step - loss: 1.7429 - acc: 0.4350 - val_loss: 2.4261 - val_acc: 0.2204\n",
      "Epoch 15/500\n",
      "4855/4855 [==============================] - 3s 711us/step - loss: 1.7182 - acc: 0.4447 - val_loss: 2.2880 - val_acc: 0.2426\n",
      "Epoch 16/500\n",
      "4855/4855 [==============================] - 3s 712us/step - loss: 1.6975 - acc: 0.4531 - val_loss: 2.3273 - val_acc: 0.2426\n",
      "Epoch 17/500\n",
      "4855/4855 [==============================] - 3s 711us/step - loss: 1.6900 - acc: 0.4393 - val_loss: 2.2654 - val_acc: 0.2593\n",
      "Epoch 18/500\n",
      "4855/4855 [==============================] - 3s 704us/step - loss: 1.6746 - acc: 0.4496 - val_loss: 2.3080 - val_acc: 0.2519\n",
      "Epoch 19/500\n",
      "4855/4855 [==============================] - 3s 696us/step - loss: 1.6667 - acc: 0.4457 - val_loss: 2.3439 - val_acc: 0.2389\n",
      "Epoch 20/500\n",
      "4855/4855 [==============================] - 3s 665us/step - loss: 1.6479 - acc: 0.4579 - val_loss: 2.2413 - val_acc: 0.2296\n",
      "Epoch 21/500\n",
      "4855/4855 [==============================] - 3s 667us/step - loss: 1.6473 - acc: 0.4575 - val_loss: 2.2275 - val_acc: 0.2648\n",
      "Epoch 22/500\n",
      "4855/4855 [==============================] - 3s 678us/step - loss: 1.6297 - acc: 0.4577 - val_loss: 2.2860 - val_acc: 0.2685\n",
      "Epoch 23/500\n",
      "4855/4855 [==============================] - 3s 702us/step - loss: 1.6274 - acc: 0.4581 - val_loss: 2.2211 - val_acc: 0.2556\n",
      "Epoch 24/500\n",
      "4855/4855 [==============================] - 4s 727us/step - loss: 1.6140 - acc: 0.4626 - val_loss: 2.3248 - val_acc: 0.2500\n",
      "Epoch 25/500\n",
      "4855/4855 [==============================] - 3s 718us/step - loss: 1.6093 - acc: 0.4653 - val_loss: 2.2559 - val_acc: 0.2537\n",
      "Epoch 26/500\n",
      "4855/4855 [==============================] - 3s 702us/step - loss: 1.5981 - acc: 0.4632 - val_loss: 2.2691 - val_acc: 0.2611\n",
      "Epoch 27/500\n",
      "4855/4855 [==============================] - 3s 697us/step - loss: 1.5967 - acc: 0.4655 - val_loss: 2.2508 - val_acc: 0.2444\n",
      "Epoch 28/500\n",
      "4855/4855 [==============================] - 3s 692us/step - loss: 1.5835 - acc: 0.4659 - val_loss: 2.2101 - val_acc: 0.2722\n",
      "Epoch 29/500\n",
      "4855/4855 [==============================] - 3s 673us/step - loss: 1.5804 - acc: 0.4676 - val_loss: 2.3541 - val_acc: 0.2278\n",
      "Epoch 30/500\n",
      "4855/4855 [==============================] - 3s 691us/step - loss: 1.5809 - acc: 0.4725 - val_loss: 2.2440 - val_acc: 0.2648\n",
      "Epoch 31/500\n",
      "4855/4855 [==============================] - 3s 712us/step - loss: 1.5747 - acc: 0.4665 - val_loss: 2.3184 - val_acc: 0.2648\n",
      "Epoch 32/500\n",
      "4855/4855 [==============================] - 3s 714us/step - loss: 1.5723 - acc: 0.4719 - val_loss: 2.2131 - val_acc: 0.2593\n",
      "Epoch 33/500\n",
      "4855/4855 [==============================] - 3s 712us/step - loss: 1.5638 - acc: 0.4766 - val_loss: 2.2804 - val_acc: 0.2574\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "def create_model(profile_data, layer_data, n_classes):\n",
    "    input_profile = Input( \n",
    "        shape=(profile_data.shape[1:]))\n",
    "    output_profile = Dense(32, activation=\"relu\")(input_profile)\n",
    "\n",
    "    input_layer = Input(shape=(layer_data.shape[1:]))\n",
    "    masking_layer = Masking(mask_value=0.0)(input_layer)\n",
    "    middle_layer = Bidirectional(\n",
    "        LSTM(16, return_sequences=True))(masking_layer)\n",
    "\n",
    "    dropout_layer = TimeDistributed(Dropout(0.2))(middle_layer)\n",
    "\n",
    "    after_dropout_layer = Bidirectional(LSTM(16))(dropout_layer)\n",
    "    #after_dropout_layer = Bidirectional(NestedLSTM(units=64, depth=2))(dropout_layer)\n",
    "    #after_dropout_layer = Bidirectional(MultiplicativeLSTM(16))(dropout_layer)\n",
    "\n",
    "    join_layer = concatenate([output_profile, after_dropout_layer])\n",
    "\n",
    "    test = Dense(16, activation=\"relu\")(join_layer)\n",
    "\n",
    "    output_final = Dense(n_classes, activation='softmax')(test)\n",
    "\n",
    "    opt = Adam(lr=0.0005, decay=1e-6)\n",
    "    model = Model(inputs=[input_profile, input_layer], outputs=output_final)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model = create_model(X_train_profile[:,:2], X_train_layer, y_train_rec.shape[1])\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit([X_train_profile[:,:2], X_train_layer],\n",
    "                    y_train_rec, epochs=500, validation_split=0.1, callbacks=[es])\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.37378714102383037, Accuracy: 0.4395848776871757, Time: 117.12031698226929\n"
     ]
    }
   ],
   "source": [
    "plot_loss(history)\n",
    "plot_accuracy(history)\n",
    "\n",
    "\n",
    "preds_RNN_val = model.predict([X_test_profile[:,:2], X_test_layer])\n",
    "preds_RNN_train = model.predict([X_train_profile[:,:2], X_train_layer])\n",
    "\n",
    "\n",
    "\n",
    "kappa = cohen_kappa_score(y_test_rec.argmax(axis=1), preds_RNN_val.argmax(axis=1))\n",
    "accuracy = accuracy_score(y_test_rec.argmax(axis=1), preds_RNN_val.argmax(axis=1))\n",
    "print(f'Kappa: {kappa}, Accuracy: {accuracy}, Time: {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform from one hot back to label\n",
    "# DNN\n",
    "actual_preds_DNN = []\n",
    "for pred in preds_DNN_val:\n",
    "    actual_preds_DNN.append(encoder_seq.classes_[np.argmax(pred)])\n",
    "data_val_dnn = X_test_seq.copy()\n",
    "\n",
    "# RNN\n",
    "actual_preds_RNN = []\n",
    "for pred in preds_RNN_val:\n",
    "    actual_preds_RNN.append(encoder_rec.classes_[np.argmax(pred)]) \n",
    "data_val_rnn = pd.DataFrame(X_test_profile[:,2], columns=['profile_id'])\n",
    "data_val_rnn.profile_id = data_val_rnn.profile_id.astype('int64')\n",
    "\n",
    "# Validation tests\n",
    "data_val = X_test.copy()\n",
    "data_val['pred_RF'] = preds_RF_val\n",
    "data_val['pred_XGB'] = preds_XGB_val\n",
    "data_val_dnn['pred_DNN'] = actual_preds_DNN\n",
    "data_val_rnn['pred_RNN'] = actual_preds_RNN\n",
    "\n",
    "data_val = data_val.merge(data_val_rnn, on='profile_id', how=\"left\")\n",
    "data_val = data_val.merge(data_val_dnn[['profile_id', 'pred_DNN']], on='profile_id', how=\"left\")\n",
    "\n",
    "data_val['pred_type'] = 'validation'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DNN\n",
    "actual_preds_DNN = []\n",
    "for pred in preds_DNN_train:\n",
    "    actual_preds_DNN.append(encoder_seq.classes_[np.argmax(pred)])\n",
    "data_train_dnn = X_train_seq.copy()\n",
    "\n",
    "# RNN\n",
    "actual_preds_RNN = []\n",
    "for pred in preds_RNN_train:\n",
    "    actual_preds_RNN.append(encoder_seq.classes_[np.argmax(pred)]) \n",
    "data_train_rnn = pd.DataFrame(X_train_profile[:,2], columns=['profile_id'])\n",
    "data_train_rnn.profile_id = data_train_rnn.profile_id.astype('int64')\n",
    "\n",
    "# Train tests\n",
    "data_train = X_train.copy()\n",
    "data_train['pred_RF'] = preds_RF_train\n",
    "data_train['pred_XGB'] = preds_XGB_train\n",
    "\n",
    "data_train_dnn['pred_DNN'] = actual_preds_DNN\n",
    "data_train_rnn['pred_RNN'] = actual_preds_RNN\n",
    "\n",
    "data_train = data_train.merge(data_train_rnn, on='profile_id', how=\"left\", suffixes=(False,False))\n",
    "data_train = data_train.merge(data_train_dnn[['profile_id', 'pred_DNN']], on='profile_id', how=\"left\")\n",
    "\n",
    "data_train['pred_type'] = 'train'\n",
    "\n",
    "data_all = pd.concat([data_train, data_val])\n",
    "\n",
    "final_data = final_data.merge(data_all, how=\"inner\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>cwrb_reference_soil_group</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>tceq_value_avg</th>\n",
       "      <th>clay_value_avg</th>\n",
       "      <th>elcosp_value_avg</th>\n",
       "      <th>orgc_value_avg</th>\n",
       "      <th>phaq_value_avg</th>\n",
       "      <th>sand_value_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>silt_value_avg_150</th>\n",
       "      <th>latitude_150</th>\n",
       "      <th>longitude_150</th>\n",
       "      <th>thickness_150</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>pred_RF</th>\n",
       "      <th>pred_XGB</th>\n",
       "      <th>pred_RNN</th>\n",
       "      <th>pred_DNN</th>\n",
       "      <th>pred_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205798</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.830317</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>-0.338778</td>\n",
       "      <td>1.969068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.412049</td>\n",
       "      <td>-1.737238</td>\n",
       "      <td>0.816626</td>\n",
       "      <td>1.811789</td>\n",
       "      <td>4</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205801</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.080485</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.497614</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>-0.415285</td>\n",
       "      <td>-1.309646</td>\n",
       "      <td>1.969068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456695</td>\n",
       "      <td>-1.741588</td>\n",
       "      <td>0.832420</td>\n",
       "      <td>-0.236316</td>\n",
       "      <td>2</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>205803</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.080485</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.929220</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.436775</td>\n",
       "      <td>-1.066929</td>\n",
       "      <td>0.719543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116923</td>\n",
       "      <td>-1.746464</td>\n",
       "      <td>0.992403</td>\n",
       "      <td>1.129087</td>\n",
       "      <td>5</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205811</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.191671</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.319068</td>\n",
       "      <td>-0.581495</td>\n",
       "      <td>1.776833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116923</td>\n",
       "      <td>-1.759613</td>\n",
       "      <td>0.872343</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>3</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205820</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.941503</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.105857</td>\n",
       "      <td>-0.662401</td>\n",
       "      <td>1.872950</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242163</td>\n",
       "      <td>-1.773091</td>\n",
       "      <td>0.885003</td>\n",
       "      <td>-0.065641</td>\n",
       "      <td>6</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>205821</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.941503</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.247148</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>-0.743306</td>\n",
       "      <td>0.335074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222848</td>\n",
       "      <td>-1.773112</td>\n",
       "      <td>0.920485</td>\n",
       "      <td>-0.406992</td>\n",
       "      <td>1</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>205826</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.163875</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.701863</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.158945</td>\n",
       "      <td>-1.066929</td>\n",
       "      <td>1.007895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562620</td>\n",
       "      <td>-1.776926</td>\n",
       "      <td>1.001344</td>\n",
       "      <td>-0.577667</td>\n",
       "      <td>2</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>205828</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.885910</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>-0.144526</td>\n",
       "      <td>-1.471457</td>\n",
       "      <td>0.815660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626581</td>\n",
       "      <td>-1.780098</td>\n",
       "      <td>0.921172</td>\n",
       "      <td>-0.236316</td>\n",
       "      <td>1</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>205829</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.024892</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.269549</td>\n",
       "      <td>-1.228740</td>\n",
       "      <td>0.911777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456695</td>\n",
       "      <td>-1.781360</td>\n",
       "      <td>0.964588</td>\n",
       "      <td>0.787737</td>\n",
       "      <td>3</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>205830</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.552351</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.383935</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>-0.416471</td>\n",
       "      <td>-0.986023</td>\n",
       "      <td>1.872950</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.412049</td>\n",
       "      <td>-1.782595</td>\n",
       "      <td>0.896370</td>\n",
       "      <td>0.787737</td>\n",
       "      <td>3</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>205835</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.635741</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.156578</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.176191</td>\n",
       "      <td>-1.390551</td>\n",
       "      <td>1.488481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902392</td>\n",
       "      <td>-1.799195</td>\n",
       "      <td>0.958387</td>\n",
       "      <td>0.531723</td>\n",
       "      <td>1</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>205839</td>\n",
       "      <td>Vertisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.719131</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>0.207566</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.039494</td>\n",
       "      <td>0.308467</td>\n",
       "      <td>-0.722217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796467</td>\n",
       "      <td>-1.722731</td>\n",
       "      <td>1.632932</td>\n",
       "      <td>0.787737</td>\n",
       "      <td>3</td>\n",
       "      <td>Vertisols</td>\n",
       "      <td>Phaeozems</td>\n",
       "      <td>Phaeozems</td>\n",
       "      <td>Gleysols</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>205840</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.191671</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.701863</td>\n",
       "      <td>0.325055</td>\n",
       "      <td>1.879035</td>\n",
       "      <td>-0.986023</td>\n",
       "      <td>-0.433865</td>\n",
       "      <td>...</td>\n",
       "      <td>2.155553</td>\n",
       "      <td>-1.730254</td>\n",
       "      <td>1.367442</td>\n",
       "      <td>0.702399</td>\n",
       "      <td>7</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Gleysols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>205846</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.191671</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.247148</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>2.076129</td>\n",
       "      <td>-0.581495</td>\n",
       "      <td>-0.529982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286809</td>\n",
       "      <td>-1.732419</td>\n",
       "      <td>1.580346</td>\n",
       "      <td>-0.748342</td>\n",
       "      <td>2</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>205858</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.969299</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.247148</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.236588</td>\n",
       "      <td>-1.390551</td>\n",
       "      <td>-0.337748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966353</td>\n",
       "      <td>-1.744170</td>\n",
       "      <td>1.520544</td>\n",
       "      <td>-0.492329</td>\n",
       "      <td>1</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>Phaeozems</td>\n",
       "      <td>Regosols</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>205861</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.913706</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-1.497614</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.581495</td>\n",
       "      <td>1.776833</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.751821</td>\n",
       "      <td>-1.750480</td>\n",
       "      <td>1.379444</td>\n",
       "      <td>3.774557</td>\n",
       "      <td>4</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>Arenosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>205866</td>\n",
       "      <td>Vertisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.080485</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>0.548602</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>0.630775</td>\n",
       "      <td>0.146656</td>\n",
       "      <td>-0.626100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392734</td>\n",
       "      <td>-1.757148</td>\n",
       "      <td>1.628531</td>\n",
       "      <td>-0.663005</td>\n",
       "      <td>2</td>\n",
       "      <td>Vertisols</td>\n",
       "      <td>Vertisols</td>\n",
       "      <td>Phaeozems</td>\n",
       "      <td>Leptosols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>205867</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.080485</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.929220</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>1.222056</td>\n",
       "      <td>-0.905118</td>\n",
       "      <td>-0.722217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.985668</td>\n",
       "      <td>-1.762606</td>\n",
       "      <td>1.400855</td>\n",
       "      <td>0.787737</td>\n",
       "      <td>6</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>Cambisols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>205873</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-0.997096</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>-0.701863</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-1.795079</td>\n",
       "      <td>0.719543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456695</td>\n",
       "      <td>-1.770991</td>\n",
       "      <td>1.491237</td>\n",
       "      <td>0.446386</td>\n",
       "      <td>6</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>205877</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>-0.934569</td>\n",
       "      <td>-1.163875</td>\n",
       "      <td>-0.47501</td>\n",
       "      <td>0.321245</td>\n",
       "      <td>-0.178067</td>\n",
       "      <td>1.616244</td>\n",
       "      <td>-1.714174</td>\n",
       "      <td>-0.914452</td>\n",
       "      <td>...</td>\n",
       "      <td>1.815782</td>\n",
       "      <td>-1.777803</td>\n",
       "      <td>1.538096</td>\n",
       "      <td>0.275710</td>\n",
       "      <td>5</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>Luvisols</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    profile_id cwrb_reference_soil_group  upper_depth  lower_depth  \\\n",
       "0       205798                  Regosols    -0.934569    -0.830317   \n",
       "1       205801                  Regosols    -0.934569    -1.080485   \n",
       "2       205803                 Cambisols    -0.934569    -1.080485   \n",
       "3       205811                  Regosols    -0.934569    -1.191671   \n",
       "4       205820                 Cambisols    -0.934569    -0.941503   \n",
       "5       205821                  Regosols    -0.934569    -0.941503   \n",
       "6       205826                  Regosols    -0.934569    -1.163875   \n",
       "7       205828                  Regosols    -0.934569    -0.885910   \n",
       "8       205829                  Regosols    -0.934569    -1.024892   \n",
       "9       205830                  Regosols    -0.934569    -0.552351   \n",
       "10      205835                  Regosols    -0.934569    -0.635741   \n",
       "11      205839                 Vertisols    -0.934569    -0.719131   \n",
       "12      205840                 Cambisols    -0.934569    -1.191671   \n",
       "13      205846                 Leptosols    -0.934569    -1.191671   \n",
       "14      205858                 Leptosols    -0.934569    -0.969299   \n",
       "15      205861                 Arenosols    -0.934569    -0.913706   \n",
       "16      205866                 Vertisols    -0.934569    -1.080485   \n",
       "17      205867                  Luvisols    -0.934569    -1.080485   \n",
       "18      205873                  Luvisols    -0.934569    -0.997096   \n",
       "19      205877                  Luvisols    -0.934569    -1.163875   \n",
       "\n",
       "    tceq_value_avg  clay_value_avg  elcosp_value_avg  orgc_value_avg  \\\n",
       "0         -0.47501       -1.383935         -0.178067        0.007764   \n",
       "1         -0.47501       -1.497614         -0.178067       -0.415285   \n",
       "2         -0.47501       -0.929220         -0.178067        0.436775   \n",
       "3         -0.47501       -1.383935         -0.178067        0.319068   \n",
       "4         -0.47501       -1.383935         -0.178067        0.105857   \n",
       "5         -0.47501       -0.247148         -0.178067        0.167053   \n",
       "6         -0.47501       -0.701863         -0.178067        0.158945   \n",
       "7         -0.47501       -1.383935         -0.178067       -0.144526   \n",
       "8         -0.47501       -1.383935         -0.178067        0.269549   \n",
       "9         -0.47501       -1.383935         -0.178067       -0.416471   \n",
       "10        -0.47501       -1.156578         -0.178067        0.176191   \n",
       "11        -0.47501        0.207566         -0.178067        0.039494   \n",
       "12        -0.47501       -0.701863          0.325055        1.879035   \n",
       "13        -0.47501       -0.247148         -0.178067        2.076129   \n",
       "14        -0.47501       -0.247148         -0.178067        0.236588   \n",
       "15        -0.47501       -1.497614         -0.178067        0.433681   \n",
       "16        -0.47501        0.548602         -0.178067        0.630775   \n",
       "17        -0.47501       -0.929220         -0.178067        1.222056   \n",
       "18        -0.47501       -0.701863         -0.178067       -0.157600   \n",
       "19        -0.47501        0.321245         -0.178067        1.616244   \n",
       "\n",
       "    phaq_value_avg  sand_value_avg     ...      silt_value_avg_150  \\\n",
       "0        -0.338778        1.969068     ...               -1.412049   \n",
       "1        -1.309646        1.969068     ...                0.456695   \n",
       "2        -1.066929        0.719543     ...                0.116923   \n",
       "3        -0.581495        1.776833     ...                0.116923   \n",
       "4        -0.662401        1.872950     ...               -1.242163   \n",
       "5        -0.743306        0.335074     ...               -0.222848   \n",
       "6        -1.066929        1.007895     ...               -0.562620   \n",
       "7        -1.471457        0.815660     ...                0.626581   \n",
       "8        -1.228740        0.911777     ...                0.456695   \n",
       "9        -0.986023        1.872950     ...               -1.412049   \n",
       "10       -1.390551        1.488481     ...               -0.902392   \n",
       "11        0.308467       -0.722217     ...                0.796467   \n",
       "12       -0.986023       -0.433865     ...                2.155553   \n",
       "13       -0.581495       -0.529982     ...                0.286809   \n",
       "14       -1.390551       -0.337748     ...                0.966353   \n",
       "15       -0.581495        1.776833     ...               -1.751821   \n",
       "16        0.146656       -0.626100     ...               -0.392734   \n",
       "17       -0.905118       -0.722217     ...                1.985668   \n",
       "18       -1.795079        0.719543     ...                0.456695   \n",
       "19       -1.714174       -0.914452     ...                1.815782   \n",
       "\n",
       "    latitude_150  longitude_150  thickness_150  n_layers    pred_RF  \\\n",
       "0      -1.737238       0.816626       1.811789         4   Regosols   \n",
       "1      -1.741588       0.832420      -0.236316         2   Regosols   \n",
       "2      -1.746464       0.992403       1.129087         5  Cambisols   \n",
       "3      -1.759613       0.872343       0.019697         3   Regosols   \n",
       "4      -1.773091       0.885003      -0.065641         6  Cambisols   \n",
       "5      -1.773112       0.920485      -0.406992         1   Regosols   \n",
       "6      -1.776926       1.001344      -0.577667         2   Regosols   \n",
       "7      -1.780098       0.921172      -0.236316         1   Regosols   \n",
       "8      -1.781360       0.964588       0.787737         3   Regosols   \n",
       "9      -1.782595       0.896370       0.787737         3   Regosols   \n",
       "10     -1.799195       0.958387       0.531723         1   Regosols   \n",
       "11     -1.722731       1.632932       0.787737         3  Vertisols   \n",
       "12     -1.730254       1.367442       0.702399         7  Cambisols   \n",
       "13     -1.732419       1.580346      -0.748342         2  Leptosols   \n",
       "14     -1.744170       1.520544      -0.492329         1  Leptosols   \n",
       "15     -1.750480       1.379444       3.774557         4  Arenosols   \n",
       "16     -1.757148       1.628531      -0.663005         2  Vertisols   \n",
       "17     -1.762606       1.400855       0.787737         6   Luvisols   \n",
       "18     -1.770991       1.491237       0.446386         6   Luvisols   \n",
       "19     -1.777803       1.538096       0.275710         5   Luvisols   \n",
       "\n",
       "     pred_XGB   pred_RNN   pred_DNN   pred_type  \n",
       "0    Regosols  Arenosols   Regosols       train  \n",
       "1    Regosols   Regosols   Regosols       train  \n",
       "2   Cambisols   Luvisols  Cambisols       train  \n",
       "3    Regosols   Regosols   Regosols       train  \n",
       "4   Cambisols  Arenosols   Regosols       train  \n",
       "5    Regosols   Regosols  Leptosols       train  \n",
       "6    Regosols   Regosols   Regosols       train  \n",
       "7    Regosols   Regosols   Regosols       train  \n",
       "8    Regosols   Regosols   Regosols       train  \n",
       "9    Regosols   Regosols   Regosols       train  \n",
       "10   Regosols   Regosols   Regosols       train  \n",
       "11  Phaeozems  Phaeozems   Gleysols  validation  \n",
       "12  Cambisols   Gleysols  Cambisols       train  \n",
       "13  Leptosols   Regosols  Leptosols       train  \n",
       "14  Phaeozems   Regosols  Leptosols       train  \n",
       "15  Arenosols  Arenosols  Arenosols       train  \n",
       "16  Vertisols  Phaeozems  Leptosols       train  \n",
       "17   Luvisols  Cambisols  Cambisols       train  \n",
       "18   Luvisols   Luvisols   Luvisols       train  \n",
       "19   Luvisols   Luvisols   Luvisols       train  \n",
       "\n",
       "[20 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Clustering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing k = 4\n",
      "Testing k = 5\n",
      "Testing k = 6\n",
      "Testing k = 7\n",
      "Testing k = 8\n"
     ]
    }
   ],
   "source": [
    "# Add to df\n",
    "for cluster in range(4, 9):\n",
    "    print(f'Testing k = {cluster}')\n",
    "    kmeans = KMeans(n_clusters=cluster, init=\"k-means++\")\n",
    "    kmeans.fit(final_data.drop(['profile_id','cwrb_reference_soil_group',\n",
    "                                 'pred_RF', 'pred_XGB', 'pred_RNN','pred_DNN', 'pred_type', 'longitude','latitude'], axis=1))\n",
    "    final_data[f'cluster_{cluster}']= kmeans.predict(final_data.drop(['profile_id','cwrb_reference_soil_group',\n",
    "                                 'pred_RF', 'pred_XGB', 'pred_RNN','pred_DNN', 'pred_type', 'longitude','latitude'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Not normalized lat long\n",
    "\n",
    "profiles = pd.read_csv(profile_file)\n",
    "profiles = profiles[['profile_id', 'latitude', 'longitude']]\n",
    "\n",
    "final_data.rename(index=str, columns={\"latitude\": \"latitude_standard\", \"longitude\": \"longitude_standard\"}, inplace=True)\n",
    "final_data = final_data.merge(profiles, how=\"inner\", left_on=[\n",
    "        'profile_id'], right_on=['profile_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['profile_id', 'cwrb_reference_soil_group', 'upper_depth', 'lower_depth',\n",
       "       'tceq_value_avg', 'clay_value_avg', 'elcosp_value_avg',\n",
       "       'orgc_value_avg', 'phaq_value_avg', 'sand_value_avg', 'silt_value_avg',\n",
       "       'latitude_standard', 'longitude_standard', 'thickness',\n",
       "       'upper_depth_10', 'lower_depth_10', 'tceq_value_avg_10',\n",
       "       'clay_value_avg_10', 'elcosp_value_avg_10', 'orgc_value_avg_10',\n",
       "       'phaq_value_avg_10', 'sand_value_avg_10', 'silt_value_avg_10',\n",
       "       'latitude_10', 'longitude_10', 'thickness_10', 'upper_depth_22.5',\n",
       "       'lower_depth_22.5', 'tceq_value_avg_22.5', 'clay_value_avg_22.5',\n",
       "       'elcosp_value_avg_22.5', 'orgc_value_avg_22.5', 'phaq_value_avg_22.5',\n",
       "       'sand_value_avg_22.5', 'silt_value_avg_22.5', 'latitude_22.5',\n",
       "       'longitude_22.5', 'thickness_22.5', 'upper_depth_45', 'lower_depth_45',\n",
       "       'tceq_value_avg_45', 'clay_value_avg_45', 'elcosp_value_avg_45',\n",
       "       'orgc_value_avg_45', 'phaq_value_avg_45', 'sand_value_avg_45',\n",
       "       'silt_value_avg_45', 'latitude_45', 'longitude_45', 'thickness_45',\n",
       "       'upper_depth_80', 'lower_depth_80', 'tceq_value_avg_80',\n",
       "       'clay_value_avg_80', 'elcosp_value_avg_80', 'orgc_value_avg_80',\n",
       "       'phaq_value_avg_80', 'sand_value_avg_80', 'silt_value_avg_80',\n",
       "       'latitude_80', 'longitude_80', 'thickness_80', 'upper_depth_150',\n",
       "       'lower_depth_150', 'tceq_value_avg_150', 'clay_value_avg_150',\n",
       "       'elcosp_value_avg_150', 'orgc_value_avg_150', 'phaq_value_avg_150',\n",
       "       'sand_value_avg_150', 'silt_value_avg_150', 'latitude_150',\n",
       "       'longitude_150', 'thickness_150', 'n_layers', 'pred_RF', 'pred_XGB',\n",
       "       'pred_RNN', 'pred_DNN', 'pred_type', 'cluster_4', 'cluster_5',\n",
       "       'cluster_6', 'cluster_7', 'cluster_8', 'latitude', 'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(10).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('mexico_k_1_layers_5_with_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estimator = clf_RF.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = list(X_train.drop('profile_id', axis=1).columns),\n",
    "                class_names = clf_RF.,\n",
    "                max_depth=5,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot([\"RF\", \"DNN\",\"GTB\", \"RNN\"], [15.98,  40.98,89.83, 116.79], color='blue')\n",
    "#ax.set( ylabel='common ylabel')\n",
    "plt.ylabel(\"Time to train (s)\")\n",
    "plt.savefig('time_train.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
